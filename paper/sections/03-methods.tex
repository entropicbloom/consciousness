\section{Methods}
\label{sec:methods}

\subsection{Overview}

To empirically test whether neural networks develop unambiguous relational representations, we designed experiments around a core principle: if representations are truly unambiguous, their content should be decodable purely from relational structure, even when indexical information (such as neuron positions or labels) is removed. Our approach involves three main components:

\begin{enumerate}
    \item \textbf{Base networks:} We train feedforward neural networks on image classification tasks (MNIST and Fashion-MNIST) using different training paradigms to generate networks with varying degrees of relational structure.
    \item \textbf{Dataset construction:} From each trained network, we extract weight matrices and construct datasets where neuron identities are deliberately obscured through random permutation, forcing any decoder to rely solely on relational information.
    \item \textbf{Decoders:} We employ two complementary approaches to decode representational content: (a) learned decoders based on self-attention architectures, and (b) geometric structure matching based on direct Gram matrix comparison.
\end{enumerate}

\subsection{Base Network Architecture and Training}

\subsubsection{Network Architecture}

We used fully-connected feedforward networks with the following specifications:
\begin{itemize}
    \item \textbf{Input layer:} 784 neurons (28Ã—28 pixels)
    \item \textbf{Hidden layers:} Two hidden layers with 50 neurons each
    \item \textbf{Output layer:} 10 neurons (one per class)
    \item \textbf{Activation:} ReLU for hidden layers, softmax for output layer
\end{itemize}

For architectural invariance experiments, we varied the hidden layer sizes by randomly sampling widths between 25 and 100 neurons, or using fixed architectures such as [100] (single hidden layer with 100 neurons).

\subsubsection{Training Paradigms}

To investigate how different training procedures affect the emergence of relational structure, we employed three training paradigms:

\begin{enumerate}
    \item \textbf{Untrained (control):} Networks with randomly initialized weights, never trained. These serve as a negative control, as random weights should not contain meaningful relational structure.

    \item \textbf{Standard backpropagation:} Networks trained with standard stochastic gradient descent and cross-entropy loss for 2 epochs.

    \item \textbf{Backpropagation with dropout:} Networks trained with dropout regularization (rate = 0.2) applied to hidden layers during training. Dropout encourages distributed representations by randomly deactivating neurons during training~\cite{baldi2013understanding}.
\end{enumerate}

For all training paradigms, we used:
\begin{itemize}
    \item Optimizer: Adam
    \item Learning rate: 0.001
    \item Batch size: 256
    \item Epochs: 2 (0 for untrained paradigm)
\end{itemize}

To generate sufficient data for decoder training and evaluation, we trained 1000 instances of each base network type using different random seeds.

\subsection{Dataset Construction for Relational Decoding}

\subsubsection{Output Neuron Class Identity Dataset}

For Experiment 1 (Section~\ref{sec:exp1}), we construct a dataset to test whether output neuron class identity can be decoded from relational structure. Let $\mathbf{W} \in \mathbb{R}^{H \times 10}$ denote the output layer weight matrix of a trained network, where $H$ is the dimensionality of the last hidden layer and the 10 columns correspond to the 10 output neurons (one per digit class 0-9).

To create a single training example:
\begin{enumerate}
    \item Apply a random permutation $\pi$ to the columns of $\mathbf{W}$, yielding $\mathbf{X} = \mathbf{W}\pi$.
    \item The target $y$ is the class index of the output neuron that ended up in the first column after permutation.
\end{enumerate}

Each of the 1000 trained networks contributes 10 data points (one per output neuron), yielding 10,000 total examples. We split these into 8,000 training and 2,000 validation examples, ensuring that all data points from the same network instance appear in only one split.

\subsubsection{Input Neuron Spatial Position Dataset}

For Experiment 2 (Section~\ref{sec:exp2}), we construct a dataset to test whether input neuron spatial position can be decoded from relational structure. Let $\mathbf{W} \in \mathbb{R}^{784 \times H}$ denote the first layer weight matrix (transposed view), where the 784 rows correspond to input pixels and $H$ is the first hidden layer size.

To create a single training example:
\begin{enumerate}
    \item Apply a random permutation $\pi$ to the rows of $\mathbf{W}$, yielding $\mathbf{X} = \pi \mathbf{W}$.
    \item Define a target function $f(i,j)$ that extracts positional information from pixel coordinates $(i,j)$, such as:
    \begin{itemize}
        \item Distance from center: $f(i,j) = \sqrt{(i-13.5)^2 + (j-13.5)^2}$
        \item Vertical position: $f(i,j) = j/27$
        \item Horizontal position: $f(i,j) = i/27$
    \end{itemize}
    \item The target $y = f(i,j)$ for the input neuron that ended up in the first row.
\end{enumerate}

\subsection{Relational Preprocessing}

To make the decoding task explicitly relational, we transform weight matrices into cosine similarity matrices that encode pairwise relationships between neurons.

For output neurons (Experiment 1), we compute:
\begin{align}
\mathbf{X}_{norm} &= \frac{\mathbf{X}}{\|\mathbf{X}\|_{col}} \\
\mathbf{X}' &= \mathbf{X}_{norm}^T \mathbf{X}_{norm}
\end{align}

where $\|\mathbf{X}\|_{col}$ denotes column-wise L2 normalization. Each element $(\mathbf{X}')_{i,j}$ represents the cosine similarity between the incoming weights of output neurons $i$ and $j$.

For input neurons (Experiment 2), we compute:
\begin{align}
\mathbf{X}_{norm} &= \frac{\mathbf{X}}{\|\mathbf{X}\|_{row}} \\
\mathbf{X}' &= \mathbf{X}_{norm} \mathbf{X}_{norm}^T
\end{align}

where each element $(\mathbf{X}')_{i,j}$ represents the cosine similarity between the outgoing weights of input neurons $i$ and $j$.

This preprocessing serves two purposes: (1) it emphasizes relational structure by encoding similarities rather than raw weights, and (2) it removes information about weight magnitudes that could provide trivial shortcuts for decoding.

\subsection{Decoder Architectures}

\subsubsection{Self-Attention Decoder}

Our primary learned decoder uses a Set Transformer architecture~\cite{vaswani2017attention} that is inherently permutation-invariant. The architecture consists of:

\begin{enumerate}
    \item \textbf{Input:} The similarity matrix $\mathbf{X}' \in \mathbb{R}^{N \times N}$, where $N$ is the number of neurons (10 for output neurons, 784 for input neurons). Rows are treated as tokens.

    \item \textbf{Embedding:} Each row (token) is linearly embedded to a hidden dimension of 128.

    \item \textbf{Multi-head self-attention layers:} Two layers of multi-head self-attention (4 heads each) process the embedded tokens. These layers compute relationships between all tokens simultaneously while maintaining permutation invariance.

    \item \textbf{Read-out:} After processing through attention layers, we extract only the representation corresponding to the first token (the target neuron).

    \item \textbf{Output layer:} A linear layer maps the extracted representation to the output space:
    \begin{itemize}
        \item For classification (Experiment 1): 10-dimensional output with cross-entropy loss
        \item For regression (Experiment 2): 1-dimensional output with mean squared error loss
    \end{itemize}
\end{enumerate}

The decoder is trained for 200 epochs using:
\begin{itemize}
    \item Optimizer: Adam
    \item Learning rate: 0.001
    \item Batch size: 64
\end{itemize}

Critically, the decoder never sees the same base network instance in both training and validation, ensuring it learns general relational principles rather than memorizing network-specific patterns.

\subsubsection{Geometric Structure Matching}

As an alternative to learned decoders, we developed a geometric matching approach that directly compares relational structures without requiring training. This method constructs a reference geometry by averaging similarity matrices from several reference networks, then decodes test networks by finding the permutation that best aligns their geometry to the reference.

Formally, given $K$ reference networks with similarity matrices $\{\mathbf{G}^{(k)}\}_{k=1}^K$, we compute:
\begin{equation}
\mathbf{G}_{ref} = \frac{1}{K} \sum_{k=1}^K \mathbf{G}^{(k)}
\end{equation}

For a test network with permuted neurons yielding similarity matrix $\mathbf{G}_{test}$, we evaluate all possible permutations $\pi$ and select:
\begin{equation}
\pi^* = \argmin_{\pi} \|\mathbf{G}_{ref} - \pi \mathbf{G}_{test} \pi^T\|_F
\end{equation}

where $\|\cdot\|_F$ denotes the Frobenius norm. The permutation $\pi^*$ that minimizes the distance to the reference geometry provides our decoding.

For output neurons with 10 classes, this requires evaluating $10! = 3,628,800$ permutations. For larger sets, we use approximation algorithms or restrict to subsets.

\subsection{Evaluation Metrics}

\begin{itemize}
    \item \textbf{Classification accuracy:} For Experiment 1, we report top-1 accuracy in identifying the correct class of the target output neuron.
    \item \textbf{$R^2$ score:} For Experiment 2, we report the coefficient of determination for predicting continuous spatial properties.
    \item \textbf{Ambiguity-Reduction Score (ARS):} A metric derived from accuracy or $R^2$ that quantifies the reduction in representational ambiguity (see Section~\ref{sec:ambiguity}).
\end{itemize}

All results report mean and standard deviation across 5 random seeds for decoder training.

\subsection{Ablation Studies}

To validate that decoders exploit full relational structure rather than local patterns, we conduct two types of ablation:

\begin{enumerate}
    \item \textbf{Target similarity only:} Provide the decoder with only the first row of $\mathbf{X}'$ (the target neuron's similarities to all others), masking out all pairwise similarities between non-target neurons.

    \item \textbf{Subset size variation:} Randomly sample subsets of neurons of varying sizes and perform decoding on the reduced relational structure.
\end{enumerate}

\subsection{Cross-Architecture Transfer}

To test whether relational structure is architecture-invariant, we train decoders on networks with one hidden layer configuration and evaluate on networks with different configurations. We also test the geometric matching approach across architectures by using reference networks of one architecture to decode test networks of another.
