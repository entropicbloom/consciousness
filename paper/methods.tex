We conducted two experiments testing whether neural networks encode representational content unambiguously through relational structure: (1) decoding digit class from output neuron connectivity, and (2) decoding spatial position from input neuron connectivity.

\subsection{Experiment 1: Decoding Digit Class from Output Neurons}

\subsubsection{Network Architecture and Training}

We trained fully-connected networks (784-50-50-10 architecture) on MNIST digit classification under three paradigms: (1) untrained (random initialization, control), (2) standard backpropagation (2 epochs), and (3) backpropagation with 20\% dropout on hidden layers \citep{baldi2013understanding}. We used 2 epochs to ensure learning while avoiding overfitting on this simple task; 20\% dropout represents a standard rate balancing regularization and capacity. We generated 1000 networks per paradigm using different random seeds. All networks used Adam optimizer with learning rate 0.001 and batch size 256.

\subsubsection{Decoding Task}

Can we determine which digit class an output neuron represents from connectivity alone? Let $W \in \mathbb{R}^{10 \times 50}$ denote the output layer weight matrix (rows = neurons). We randomly permute rows to create $X$ and define label $y$ as the class of the first-row neuron, ensuring neuron position conveys no information about class identity.

\subsubsection{Relational Structure Extraction}

We extract relational structure via cosine similarities, which measure directional alignment regardless of magnitude, making them robust to weight scale variations across networks. After L2-normalizing rows of $X$ to get $X_{\text{norm}}$, we compute the Gram matrix $X' = X_{\text{norm}} X_{\text{norm}}^T$, where $(X')_{i,j}$ is the cosine similarity between neurons $i$ and $j$.

\subsubsection{Decoding Methods}

\paragraph{Geometric Matching.} We construct a reference Gram matrix $G_{\text{ref}}$ by averaging the cosine similarity matrices from 5 networks with known class ordering. The logic is: if networks consistently encode the same relational structure across training runs, then a test network's Gram matrix should closely match the reference when its neurons are correctly aligned. For each of 10 test networks with unknown ordering, we search over all possible permutations of its output neurons to find the class assignment $\hat{\sigma}$ that minimizes the Frobenius distance between the permuted test Gram matrix and the reference:
\begin{equation}
\hat{\sigma} = \arg\min_{\sigma} \|G_{\text{ref}} - P_{\sigma} G_{\text{test}} P_{\sigma}^T\|_F
\end{equation}
where $P_{\sigma}$ is a permutation matrix and $\|A\|_F = \sqrt{\sum_{i,j} A_{i,j}^2}$ is the Frobenius norm. This approach tests whether relational geometry alone is sufficiently consistent across network instances to identify neuron class identity.

\paragraph{Learned Decoder.} We trained a transformer-based decoder \citep{vaswani2017attention} with self-attention layers, treating rows of $X'$ as tokens. Crucially, we do not use positional encodings (as in the original transformer architecture) to ensure permutation invariance: the only positional information is which row corresponds to the target neuron. Training used 800 networks (8000 data points), validation used 200 held-out networks (2000 data points), ensuring the decoder learns general relational patterns. We trained 5 decoder instances with different random seeds to assess variance.

\subsubsection{Relational Structure Necessity}

To determine whether the full relational geometry is necessary or if local neighborhoods suffice, we conducted an ablation by providing the decoder with only the first row of $X'$ (the target neuron's cosine similarities with all other neurons), while masking out all pairwise similarities that do not involve the target neuron. This tests whether a neuron's class identity can be determined from its local relationships alone or requires information about the broader geometric organization.

\subsubsection{Architecture Invariance}

To test whether relational structure depends on specific architectural choices, we evaluated cross-architecture transfer using the geometric matching approach. We tested three different hidden layer architectures (50-50, 25-25, and 100) in a 3$\times$3 design, constructing reference Gram matrices from networks of each architecture and decoding test networks of each architecture, yielding decoding accuracy for all nine combinations. This assesses whether representational content is encoded in an architecture-invariant manner.

\subsubsection{Dataset Discrimination}

Using the transformer-based decoder architecture described above with random output-neuron permutations, we trained a binary classifier to distinguish whether a network was trained on MNIST or Fashion-MNIST from output layer weights alone. This tests whether dataset identity is encoded in relational geometry.

\subsection{Experiment 2: Decoding Spatial Position from Input Neurons}

Can we decode which pixel position an input neuron represents from its connectivity? Using the same networks, we focus on the first-layer weight matrix $W \in \mathbb{R}^{784 \times 50}$ (columns = input neurons). After permuting columns, we decode distance from center for the target neuron, where for a pixel at grid position $(i,j)$ in the $28 \times 28$ image:
\begin{equation}
f(i,j) = \sqrt{(i-13.5)^2 + (j-13.5)^2}
\end{equation}
This measures Euclidean distance from the image center at (13.5, 13.5).

Relational structure is extracted via column-wise cosine similarities: $X' = X_{\text{norm}}^T X_{\text{norm}}$. Due to the larger neuron count (784 vs.\ 10), we use only the learned decoder (same transformer architecture, now performing regression): searching through 784! permutations is computationally intractable. Performance is evaluated using $R^2$ score. We apply the same local vs.\ global structure ablation as in Experiment 1 to assess whether the full relational geometry is necessary for spatial position decoding.

\subsection{Quantifying Ambiguity Reduction}

We compute Ambiguity Reduction Scores (ARS) to connect decoding performance with our theoretical framework:
\begin{equation}
\text{ARS} = 1 - \frac{H(I|R,C)}{H_{\max}}
\end{equation}
where $H(I|R,C)$ is conditional entropy given representation $R$ and context $C$, and $H_{\max}$ is maximum entropy. For output neuron class decoding (Experiment 1), we use geometric matching accuracies; for input neuron position decoding (Experiment 2), we use learned decoder $R^2$ scores.

For classification with accuracy $A$ and $K$ classes, Fano's inequality yields:
\begin{equation}
\text{ARS} \geq 1 - \frac{h_b(1-A) + (1-A)\log_2(K-1)}{\log_2 K}
\end{equation}
where $h_b(p) = -p\log_2(p) - (1-p)\log_2(1-p)$.

For regression with $R^2$ score (assuming Gaussian residuals, $\text{Var}(Y)=1$):
\begin{equation}
\text{ARS} \geq \frac{\log_2[1/(1-R^2)]}{\log_2(2\pi e)} \approx \frac{\log_2[1/(1-R^2)]}{4.094}
\end{equation}
