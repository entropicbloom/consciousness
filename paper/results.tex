\subsection{Experiment 1: Output Neuron Class Decoding}

\subsubsection{Learned Decoder Performance}

Output neuron class identity can be decoded from relational structure well above chance (Figure~\ref{fig:decoder-accuracy}).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{../figures/decoder-validation-accuracy-training-paradigms.png}
    \caption{Decoder validation accuracy across training paradigms. The decoder achieves approximately 25\% accuracy for standard backpropagation networks and 75\% accuracy for dropout networks, compared to 10\% chance level (observed for untrained networks). Error bars represent standard deviation across 5 random seeds.}
    \label{fig:decoder-accuracy}
\end{figure}

Untrained networks achieve 10\% accuracy (chance level), validating our experimental design. Standard backpropagation reaches 25\% (above chance), while dropout achieves 75\%---a threefold improvement. Notably, the underlying MNIST classifiers perform identically regardless of dropout (Figure~\ref{fig:mnist-accuracy}), showing that representational ambiguity is orthogonal to task performance.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\textwidth]{../figures/mnist-model-validation-accuracies.png}
    \caption{Validation accuracies of underlying MNIST models. Despite similar classification performance, dropout and standard training produce dramatically different levels of representational ambiguity.}
    \label{fig:mnist-accuracy}
\end{figure}

\subsubsection{Geometric Matching Results}

Geometric matching (directly comparing relational geometries without training) achieves even higher accuracies (Table~\ref{tab:gram-accuracy}).

\begin{table}[htbp]
    \centering
    \begin{tabular}{lcc}
        \toprule
        Training Paradigm & Accuracy & Std Dev \\
        \midrule
        Untrained & 0.100 & 0.155 \\
        Standard backpropagation & 0.383 & 0.441 \\
        Dropout & \textbf{1.000} & \textbf{0.000} \\
        \bottomrule
    \end{tabular}
    \caption{Gram matrix decoding accuracies. Dropout networks achieve perfect 100\% accuracy with zero variance, indicating completely unambiguous relational encoding of class identity.}
    \label{tab:gram-accuracy}
\end{table}

Dropout networks achieve perfect 100\% accuracy with zero variance, demonstrating that their relational geometries unambiguously specify class identity. This remarkable result shows that the relational structure alone—without any information about neuron ordering or training procedure—completely determines what each neuron represents.

Figure~\ref{fig:perm-distances} reveals the underlying cause: dropout creates a substantial gap between the correct permutation and all incorrect alternatives, while standard backpropagation shows only small margins. This geometric clarity explains why both our learned decoder (75\%) and direct matching (100\%) achieve their best performance on dropout networks.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{../figures/perm_distances_no_dropout.png}
        \caption{Standard backpropagation}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \includegraphics[width=\textwidth]{../figures/perm_distances_dropout.png}
        \caption{Dropout training}
    \end{subfigure}
    \caption{Frobenius distances between test and reference Gram matrices for all permutations. Red dots indicate the true permutation. Dropout training creates a clear separation between correct and incorrect permutations.}
    \label{fig:perm-distances}
\end{figure}

\subsubsection{Relational Structure Necessity}

To determine whether the entire relational geometry is necessary or if local neighborhoods suffice, we provided the decoder with only the target neuron's similarity vector to all other neurons, masking out pairwise similarities between non-target neurons. Figure~\ref{fig:target-only-output} shows that accuracy drops substantially when this broader geometric context is removed. This demonstrates that a neuron's representational content cannot be determined from its local relationships alone—the decoder requires information about how the entire output population is organized relative to each other.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\textwidth]{../figures/target-similarity-only-output-neurons.png}
    \caption{Decoder accuracy when provided only the target neuron's local neighborhood versus full relational structure. The complete geometry is essential for accurate decoding.}
    \label{fig:target-only-output}
\end{figure}

\subsubsection{Architecture Invariance}

A key question is whether relational structure depends on specific architectural choices or represents a more fundamental property. We evaluated cross-architecture transfer by using reference networks of one architecture to decode test networks with different hidden layer widths. Figure~\ref{fig:cross-arch} shows strong performance across architectural variations, demonstrating that the relational geometry encoding class identity is largely architecture-invariant. This suggests that representational content is encoded in a manner that transcends implementation details.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{../figures/cross_architecture_heatmap_accuracy.png}
    \caption{Cross-architecture transfer accuracy. Strong performance across different architectures demonstrates that relational structure is largely architecture-invariant.}
    \label{fig:cross-arch}
\end{figure}

\subsubsection{Dataset Discrimination}

Dataset identity (MNIST vs.\ Fashion-MNIST) can be classified from relational structure with near-perfect accuracy for dropout (99.8\% $\pm$ 0.1\%) and clearly above chance for standard training (84.3\% $\pm$ 0.8\%). This shows that dataset identity---a major component of context $C$---is encoded in relational geometry.

\subsection{Experiment 2: Input Neuron Spatial Position Decoding}

While digit class identity is abstract, spatial position provides a more direct connection to phenomenal properties like visual field location. We asked whether input neurons encode their pixel positions through relational structure. Figure~\ref{fig:input-distance} shows that they do: the decoder achieves $R^2 = 0.844$ (standard backpropagation) and $R^2 = 0.695$ (dropout), both substantially above the untrained baseline ($R^2 \approx 0$).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{../figures/input-neuron-distance-prediction-accuracy.png}
    \caption{Decoder $R^2$ score for predicting input neuron distance from center. Unlike output neurons, standard backpropagation yields higher accuracy than dropout for this task.}
    \label{fig:input-distance}
\end{figure}

Interestingly, the pattern reverses compared to output neurons: standard backpropagation yields higher spatial decoding accuracy than dropout. This dissociation suggests that different layers and representational types may be subject to different optimization dynamics under dropout training. Nevertheless, as in Experiment 1, providing the decoder with the full relational structure substantially outperforms using only local neighborhoods (Figure~\ref{fig:target-only-input}), confirming that broader geometric context enhances decoding across different representational domains.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\textwidth]{../figures/target-similarity-only-input-pixels.png}
    \caption{Decoder performance for input neurons when using only local neighborhood versus full relational structure.}
    \label{fig:target-only-input}
\end{figure}

\subsection{Ambiguity Reduction Scores}

Table~\ref{tab:ars-scores} summarizes the Ambiguity Reduction Scores (ARS) computed from our experimental results.

\begin{table}[htbp]
    \centering
    \begin{tabular}{llcc}
        \toprule
        Experiment & Training & Performance & ARS (lower bound) \\
        \midrule
        Output (class) & Dropout & Acc = 1.000 & 1.000 \\
        Output (class) & Standard & Acc = 0.383 & 0.122 \\
        Output (class) & Untrained & Acc = 0.120 & 0.001 \\
        \midrule
        Input (position) & Dropout & $R^2 = 0.695$ & 0.419 \\
        Input (position) & Standard & $R^2 = 0.844$ & 0.654 \\
        Input (position) & Untrained & $R^2 = -0.008$ & 0.000 \\
        \bottomrule
    \end{tabular}
    \caption{Ambiguity Reduction Scores. An ARS of 1.0 indicates complete disambiguation---zero conditional entropy. Dropout networks achieve perfect disambiguation for output neuron class identity.}
    \label{tab:ars-scores}
\end{table}

The perfect ARS of 1.0 for dropout output neurons indicates $H(I|R,C) = 0$: relational structure completely determines representational content within the experimental context. Even for the more challenging spatial position task, we achieve ARS values of 0.419–0.654, demonstrating substantial ambiguity reduction. These results provide quantitative support for the theoretical claim that neural representations can approach the unambiguous encoding required by theories of consciousness.
